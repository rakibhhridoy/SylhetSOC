import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from mpl_toolkits.mplot3d import Axes3D
from scipy.interpolate import griddata
warnings.filterwarnings("ignore", category=UserWarning)


pt = pd.read_csv("data/PresentTopSoil.csv")
ps = pd.read_csv("data/PresentSubSoil.csv")


pt.columns


import ee
import geemap

# Authenticate and initialize Google Earth Engine
ee.Authenticate()   # Follow on‑screen prompt in your browser
ee.Initialize(project="ee-arsenicbd")


import geopandas as gpd

shp_path = 'gis/StudyArea.shp'
gdf = gpd.read_file(shp_path)
study_area = geemap.gdf_to_ee(gdf)


def add_ndvi(image):
    ndvi = image.normalizedDifference(['B5','B4']).rename('NDVI')  # for Landsat 8; adjust bands for 5/7
    return image.addBands(ndvi)

# Merge Landsat 5, 7, 8 collections with NDVI
landsat5 = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \
              .filterBounds(study_area) \
              .map(lambda img: add_ndvi(img.resample('bicubic')))

landsat7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \
              .filterBounds(study_area) \
              .map(lambda img: add_ndvi(img.resample('bicubic')))

landsat8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \
              .filterBounds(study_area) \
              .map(lambda img: add_ndvi(img.resample('bicubic')))

landsat_all = landsat5.merge(landsat7).merge(landsat8)


def yearly_mean_ndvi(year):
    start_date = ee.Date.fromYMD(year, 1, 1)
    end_date = start_date.advance(1, 'year')
    yearly_images = landsat_all.filterDate(start_date, end_date)
    mean_ndvi = yearly_images.select('NDVI').mean().clip(study_area)
    return mean_ndvi.reduceRegion(
        reducer=ee.Reducer.mean(),
        geometry=study_area,
        scale=30,
        bestEffort=True
    ).get('NDVI')

years = list(range(1985, 2025))  # adjust timeframe if necessary

# Convert to ee.List and map
def to_feature(year):
    val = ee.Number(yearly_mean_ndvi(year))
    return ee.Feature(None, {'year': year, 'mean_ndvi': val})

features = ee.FeatureCollection(ee.List(years).map(lambda y: to_feature(y)))


def annual_mean(year):
    year = ee.Number(year)
    start = ee.Date.fromYMD(year,1,1)
    end = start.advance(1,'year')

    # Compute mean NDVI image for this year
    mean_image = (landsat
                  .filterDate(start, end)
                  .select('NDVI')
                  .mean()
                  .clip(roi))

    # Reduce to a single mean value over the ROI
    # reduceRegion returns a dictionary; specify a default value if 'NDVI' is missing
    mean_dict = mean_image.reduceRegion(
        reducer=ee.Reducer.mean(),
        geometry=roi,
        scale=30,
        bestEffort=True,
    )

    # Safely get the NDVI value; assign NaN if key doesn’t exist
    ndvi_value = ee.Dictionary(mean_dict).get('NDVI', ee.Number(float('nan')))

    return ee.Feature(None, {
        'year': year,
        'mean_ndvi': ndvi_value
    })



# NDVI functions for Level-2 Surface Reflectance datasets
def add_ndvi_l5(img):
    ndvi = img.normalizedDifference(['SR_B4', 'SR_B3']).rename('NDVI')
    return img.addBands(ndvi)

def add_ndvi_l7(img):
    ndvi = img.normalizedDifference(['SR_B4', 'SR_B3']).rename('NDVI')
    return img.addBands(ndvi)

def add_ndvi_l8(img):
    ndvi = img.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')
    return img.addBands(ndvi)

# Load and map collections with the corrected NDVI functions
l5 = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2').filterBounds(roi).map(add_ndvi_l5)
l7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2').filterBounds(roi).map(add_ndvi_l7)
l8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2').filterBounds(roi).map(add_ndvi_l8)

landsat = l5.merge(l7).merge(l8)

# Annual mean function with a sentinel value for missing NDVI
def annual_mean(year):
    year = ee.Number(year)
    start = ee.Date.fromYMD(year, 1, 1)
    end = start.advance(1, 'year')
    mean_image = (landsat
                  .filterDate(start, end)
                  .select('NDVI')
                  .mean()
                  .clip(roi))
    mean_dict = mean_image.reduceRegion(
        reducer=ee.Reducer.mean(),
        geometry=roi,
        scale=30,
        bestEffort=True
    )
    ndvi_value = ee.Dictionary(mean_dict).get('NDVI', ee.Number(-9999))
    return ee.Feature(None, {'year': year, 'mean_ndvi': ndvi_value})

years = ee.List.sequence(1985, 2024)
annual_fc = ee.FeatureCollection(years.map(annual_mean))
annual_data = annual_fc.getInfo()['features']

df = pd.DataFrame({
    'year': [f['properties']['year'] for f in annual_data],
    'mean_ndvi': [f['properties']['mean_ndvi'] for f in annual_data]
})

# Filter out sentinel values (-9999)
df = df[df['mean_ndvi'] != -9999]


df.columns


df.plot(x='year', y='mean_ndvi')


df.to_csv('geodata/ndvi_changes.csv')


shp_path = 'gis/StudyArea.shp'
gdf = gpd.read_file(shp_path)
roi_fc = geemap.gdf_to_ee(gdf)  
roi = roi_fc.geometry()

def add_ndvi_l5(img):
    ndvi = img.normalizedDifference(['SR_B4', 'SR_B3']).rename('NDVI')
    return img.addBands(ndvi)

def add_ndvi_l7(img):
    ndvi = img.normalizedDifference(['SR_B4', 'SR_B3']).rename('NDVI')
    return img.addBands(ndvi)

def add_ndvi_l8(img):
    ndvi = img.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')
    return img.addBands(ndvi)

l5 = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2').filterBounds(roi).map(add_ndvi_l5)
l7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2').filterBounds(roi).map(add_ndvi_l7)
l8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2').filterBounds(roi).map(add_ndvi_l8)

landsat = l5.merge(l7).merge(l8)

def annual_mean(year):
    year = ee.Number(year)
    start = ee.Date.fromYMD(year, 1, 1)
    end   = start.advance(1, 'year')
    mean_image = (landsat
                  .filterDate(start, end)
                  .select('NDVI')
                  .mean()
                  .clip(roi))
    mean_dict = mean_image.reduceRegion(
        reducer=ee.Reducer.mean(),
        geometry=roi,
        scale=30,
        bestEffort=True,
        maxPixels=1e13
    )
    # use -9999 as a sentinel value for missing data
    ndvi_value = ee.Dictionary(mean_dict).get('NDVI', ee.Number(-9999))
    return ee.Feature(None, {'year': year, 'mean_ndvi': ndvi_value})

years = ee.List.sequence(1985, 2024)
annual_fc = ee.FeatureCollection(years.map(annual_mean))

annual_data = annual_fc.getInfo()['features']
df = pd.DataFrame({
    'year': [f['properties']['year'] for f in annual_data],
    'mean_ndvi': [f['properties']['mean_ndvi'] for f in annual_data]
})

df['mean_ndvi'] = df['mean_ndvi'].replace(-9999, np.nan)

# Biomass (t/ha/year) = 11.59 * NDVI^2 – 4.96 * NDVI + 0.76
df['biomass_t_ha_yr'] = 11.59 * df['mean_ndvi']**2 - 4.96 * df['mean_ndvi'] + 0.76
df


df.to_csv("geodata/biomass_ndvi.csv")


shp_path = 'gis/StudyArea.shp'
gdf = gpd.read_file(shp_path)
roi_fc = geemap.gdf_to_ee(gdf)  # convert geopandas GeoDataFrame to ee.FeatureCollection
roi = roi_fc.geometry()

# Load ESA CCI AGB ImageCollection
agb_col = ee.ImageCollection("projects/sat-io/open-datasets/ESA/ESA_CCI_AGB")

# Map a function that sets a 'year' property from system:time_start
def set_year(img):
    year = ee.Date(img.get('system:time_start')).get('year')
    return img.set('year', year)

agb_col = agb_col.map(set_year)

# Get unique years in the collection and convert to Python list
years_in_dataset = agb_col.aggregate_array('year').distinct().getInfo()

# Define the full range of years you want (1985–2025)
full_years = list(range(1985, 2026))

# Compute mean biomass and total biomass for each year in the dataset;
# use None for years without data.
def get_biomass_for_year(y):
    if y in years_in_dataset:
        img = agb_col.filter(ee.Filter.eq('year', y)).first()
        # First band stores AGB (Mg/ha):contentReference[oaicite:1]{index=1}.
        agb_band = img.select(0)
        mean_dict = agb_band.reduceRegion(
            reducer=ee.Reducer.mean(),
            geometry=roi,
            scale=100,      # dataset native resolution (~100 m)
            bestEffort=True,
            maxPixels=1e13
        )
        # Extract the mean value using the band name (band index 0)
        band_name = agb_band.bandNames().get(0).getInfo()
        mean_val = mean_dict.getInfo().get(band_name)
        # Compute total AGB (Mg) by multiplying mean by area (ha)
        area_ha = roi.area().getInfo() / 10000.0
        total_biomass = mean_val * area_ha if mean_val is not None else None
        return mean_val, total_biomass
    else:
        # No data for this year
        return None, None

# Build a list of dictionaries with year, mean AGB and total AGB
data = []
for year in full_years:
    mean_agb, total_agb = get_biomass_for_year(year)
    # Use NaN for missing data
    data.append({
        'year': year,
        'mean_agb_Mg_per_ha': mean_agb if mean_agb is not None else np.nan,
        'total_agb_Mg': total_agb if total_agb is not None else np.nan
    })

df = pd.DataFrame(data)
df


df.to_csv("geodata/biomass_agb.csv")
